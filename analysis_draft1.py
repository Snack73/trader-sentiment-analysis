# -*- coding: utf-8 -*-
"""analysis_draft1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ei0pamKy3neSEc9yhs48isHZps_bXLga

# Importing requirements and setting up env
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
from scipy.stats import f_oneway
import warnings

plt.style.use('default')
sns.set_palette("husl")

"""# Loading datasets

"""

try:
    trader_data = pd.read_csv('/content/dataset_assignment/historical_data.csv') # Load Historical Trader Data
    sentiment_data = pd.read_csv('/content/dataset_assignment/fear_greed_index.csv') # Load Fear & Greed Index Data
    print("No issues, congo!")

except FileNotFoundError as e:
    print(f"Error loading data: {e}")
    exit()

print("Trader Data Shape:", trader_data.shape)
print("Sentiment Data Shape:", sentiment_data.shape)

"""# Pre=processing Data"""

# Cleaning trader data
trader_data.columns = trader_data.columns.str.replace(' ', '_') # removing spaces
trader_data['Timestamp_IST'] = pd.to_datetime(trader_data['Timestamp_IST'], format='%d-%m-%Y %H:%M')
trader_data['date'] = trader_data['Timestamp_IST'].dt.date

numerical_cols = ['Execution_Price', 'Size_Tokens', 'Size_USD', 'Closed_PnL'] # clean numerical columns
for col in numerical_cols:
    trader_data[col] = pd.to_numeric(trader_data[col], errors='coerce')


trader_data.dropna(subset=numerical_cols, inplace=True) # maybe missing values

# Clean sentiment data
sentiment_data['date'] = pd.to_datetime(sentiment_data['date']).dt.date


# sentiment score for correlation analysis
sentiment_mapping = {
    'Extreme Fear': 1,
    'Fear': 2,
    'Neutral': 3,
    'Greed': 4,
    'Extreme Greed': 5
}
sentiment_data['sentiment_score'] = sentiment_data['classification'].map(sentiment_mapping)
print("pre-processing done")

"""# integrating data

"""

merged_data = trader_data.merge(
    sentiment_data[['date', 'classification', 'sentiment_score']], on='date', how='inner'
)
print(f"Merged data shape: {merged_data.shape}")

"""# EDA and vizualization"""

plt.figure(figsize=(10, 5))
plt.title('Market Sentiment Distribution', fontsize=16)
sentiment_counts = merged_data['classification'].value_counts()
plt.pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=90)
plt.savefig('eda_sentiment_distribution.png')
plt.show()

fig, axes = plt.subplots(2, 2, figsize=(15, 10))
fig.suptitle('Trader Performance Overview', fontsize=16)
sentiment_order = ['Extreme Fear', 'Fear', 'Neutral', 'Greed', 'Extreme Greed']

# PnL distribution
axes[0, 0].hist(merged_data['Closed_PnL'], bins=50, edgecolor='black', range=(-500, 500)) # Range to focus on main distribution
axes[0, 0].set_title('Closed PnL Distribution (Clipped)')
axes[0, 0].set_xlabel('Closed PnL')

# Trade size distribution
axes[0, 1].hist(merged_data['Size_USD'], bins=50, edgecolor='black', range=(0, 50000)) # Range to focus on main distribution
axes[0, 1].set_title('Trade Size (USD) Distribution (Clipped)')
axes[0, 1].set_xlabel('Size (USD)')

# Side distribution
side_counts = merged_data['Side'].value_counts()
axes[1, 0].bar(side_counts.index, side_counts.values)
axes[1, 0].set_title('Buy vs Sell Distribution')

# Performance by sentiment
sentiment_performance = merged_data.groupby('classification')['Closed_PnL'].mean()
axes[1, 1].bar(sentiment_performance.index, sentiment_performance.values)
axes[1, 1].set_title('Average PnL by Market Sentiment')
axes[1, 1].tick_params(axis='x', rotation=45)

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.savefig('eda_trader_performance_overview.png')
plt.show()

"""# analysis: sentiment vs performance"""

print("Core Analysis - sentiment vs performance")

# adding logical order for sentiment classifications
sentiment_order = ['Extreme Fear', 'Fear', 'Neutral', 'Greed', 'Extreme Greed']

# prof&Loss Analysis by Sentiment
# detailed statistical summary of performance for all category
sentiment_stats = merged_data.groupby('classification').agg({
    'Closed_PnL': ['count', 'mean', 'median', 'std', 'sum'],
    'Size_USD': 'mean'
}).round(4)

# statistical summary
print("prof&Loss STATISTICS BY SENTIMENT")
print(sentiment_stats)

# box plot to visualize the distribution of prof&Loss of all sentiments
plt.figure(figsize=(12, 6))
sns.boxplot(data=merged_data, x='classification', y='Closed_PnL', order=sentiment_order)
plt.title('PnL Distribution by Market Sentiment', fontsize=16)
plt.ylim(-500, 500)  # Clip y-axis to better visualize the main distribution
plt.xlabel('Sentiment Classification')
plt.ylabel('Closed PnL (USD)')
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('core_pnl_by_sentiment_boxplot.png')
plt.show()

# trade behaviour analysis
# statistical summary of buy vs. sell behaviour in al sentiments
behavior_analysis = merged_data.groupby(['classification', 'Side']).agg({
    'Closed_PnL': ['count', 'mean'],
    'Size_USD': 'mean'
}).round(4)

# print the behaviour summary
print("TRADING BEHAVIOR BY SENTIMENT AND SIDE")
print(behavior_analysis)

# generate plot to visualize trading behaviour
fig, axes = plt.subplots(1, 2, figsize=(16, 6))
fig.suptitle('trading behavior analysis', fontsize=16)

# plot a: trade count by sentiment and side (stacked bar)
trade_counts = merged_data.groupby(['classification', 'Side']).size().unstack(fill_value=0).reindex(sentiment_order)
trade_counts.plot(kind='bar', ax=axes[0], stacked=True)
axes[0].set_title('trade count by sentiment and side')
axes[0].set_ylabel('number of trades')
axes[0].tick_params(axis='x', rotation=45)

# plot b: avg prof&Loss by sentiment and side (grouped bar)
avg_pnl = merged_data.groupby(['classification', 'Side'])['Closed_PnL'].mean().unstack(fill_value=0).reindex(sentiment_order)
avg_pnl.plot(kind='bar', ax=axes[1])
axes[1].set_title('average prof&Loss by sentiment and side')
axes[1].set_ylabel('avg prof&Loss (USD)')
axes[1].tick_params(axis='x', rotation=45)

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.savefig('core_trading_behavior.png')
plt.show()

print("core analysis done!")

"""# trade segments - pattern discovery"""

print("Segmenting Traders")
trader_performance = merged_data.groupby('Account').agg(
    total_pnl=('Closed_PnL', 'sum'),
    avg_pnl=('Closed_PnL', 'mean'),
    trade_count=('Closed_PnL', 'count'),
    avg_size=('Size_USD', 'mean')
).round(4)

# defining performance category based on total prof&loss quantiles
def categorize_trader(total_pnl, quantiles):
    if total_pnl > quantiles[0.8]: return 'Top 20%'
    if total_pnl > quantiles[0.6]: return '60-80%'
    if total_pnl > quantiles[0.4]: return '40-60%'
    if total_pnl > quantiles[0.2]: return '20-40%'
    return 'Bottom 20%'

pnl_quantiles = trader_performance['total_pnl'].quantile([0.2, 0.4, 0.6, 0.8])
trader_performance['category'] = trader_performance['total_pnl'].apply(lambda x: categorize_trader(x, pnl_quantiles))
print("TRADER PERFORMANCE CATEGORIES")
print(trader_performance['category'].value_counts())

# adding trader categories back to main dataset
merged_data = merged_data.merge(
    trader_performance[['category']],
    left_on='Account',
    right_index=True,
    how='left'
)

# Heatmap of average PnL: Trader Category vs Market Sentiment
sentiment_order = ['Extreme Fear', 'Fear', 'Neutral', 'Greed', 'Extreme Greed']
category_order = ['Top 20%', '60-80%', '40-60%', '20-40%', 'Bottom 20%']

pivot_pnl = merged_data.groupby(['category', 'classification'])['Closed_PnL'].mean().unstack().reindex(index=category_order, columns=sentiment_order)

plt.figure(figsize=(12, 7))
sns.heatmap(pivot_pnl, annot=True, cmap='RdYlGn', center=0, fmt='.2f')
plt.title('Average PnL Heatmap: Trader Category vs Market Sentiment', fontsize=16)
plt.xlabel('Market Sentiment')
plt.ylabel('Trader Performance Category')
plt.tight_layout()
plt.savefig('advanced_pnl_heatmap.png')
plt.show()

print("advanced analysis heatmap saved.")

"""# risk analysis"""

print("risk analysis")

# define the logical order for sentiment classifications
sentiment_order = ['Extreme Fear', 'Fear', 'Neutral', 'Greed', 'Extreme Greed']

# win rate analysis
merged_data['is_winning_trade'] = (merged_data['Closed_PnL'] > 0).astype(int)
win_rates = merged_data.groupby('classification')['is_winning_trade'].mean()

plt.figure(figsize=(10, 6))
bars = plt.bar(win_rates.index, win_rates.values)
plt.title('Win Rate by Market Sentiment', fontsize=16)
plt.ylabel('Win Rate')
plt.xlabel('Sentiment Classification')
plt.ylim(0, max(win_rates.values) * 1.2)
for bar, rate in zip(bars, win_rates.values):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
             f'{rate:.1%}', ha='center', va='bottom')

plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('risk_win_rate_by_sentiment.png')
plt.show()

# correlation analysis
correlation_data = merged_data[['sentiment_score', 'Size_USD', 'Closed_PnL']].corr()
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_data, annot=True, cmap='coolwarm', center=0)
plt.title('Correlation Matrix: Sentiment, Trade Size, and PnL', fontsize=16)
plt.tight_layout()
plt.savefig('risk_correlation_matrix.png')
plt.show()

print("risk analysis plots done")

"""# Key insights"""

# key insight generation
sentiment_performance = merged_data.groupby('classification')['Closed_PnL'].mean()
win_rates = merged_data.groupby('classification')['is_winning_trade'].mean()
key_insights = {
    "Best Performing Sentiment": f"{sentiment_performance.idxmax()} (Avg PnL: ${sentiment_performance.max():.2f})",
    "Worst Performing Sentiment": f"{sentiment_performance.idxmin()} (Avg PnL: ${sentiment_performance.min():.2f})",
    "Highest Win Rate Sentiment": f"{win_rates.idxmax()} ({win_rates.max():.1%})",
    "Lowest Win Rate Sentiment": f"{win_rates.idxmin()} ({win_rates.min():.1%})"
}

# final summary
summary = f"""
SUMMARY: Bitcoin Market Sentiment & Trader Performance Analysis

DATASET OVERVIEW:
- Analysis Period: {merged_data['date'].min()} to {merged_data['date'].max()}
- Total Trades Analyzed: {len(merged_data):,}
- Unique Traders: {merged_data['Account'].nunique():,}

PERFORMANCE VS. SENTIMENT (Average PnL per trade):
{merged_data.groupby('classification')['Closed_PnL'].mean().round(2).to_string()}

KEY INSIGHTS:
"""
# Loop through the insights dictionary to add each one to the summary
for key, value in key_insights.items():
    summary += f"- {key}: {value}\n"

summary += f"""
WIN RATE ANALYSIS (% of profitable trades):
{(win_rates * 100).round(1).to_string()}%

CONCLUSION:
This analysis reveals a distinct relationship between market sentiment and trading performance.
Traders achieved the highest average profits (${sentiment_performance.max():.2f}/trade) and the highest
win rate ({win_rates.max():.1%}) during periods of 'Extreme Greed'. This indicates that during
peak market optimism, trades were both more frequently profitable and generated higher returns
on average. Conversely, the lowest average profitability occurred during '{sentiment_performance.idxmin()}'
periods, suggesting traders should exercise increased caution when market sentiment is neutral or fearful.
"""

# saving deliverables
with open('analysis_summary.txt', 'w') as f:
    f.write(summary)
print("\n'analysis_summary.txt' saved successfully.")

def export_data():
    # Create and save a detailed summary by sentiment
    sentiment_summary = merged_data.groupby('classification').agg(
        trade_count=('Closed_PnL', 'count'),
        mean_pnl=('Closed_PnL', 'mean'),
        total_pnl=('Closed_PnL', 'sum'),
        mean_size_usd=('Size_USD', 'mean'),
        total_size_usd=('Size_USD', 'sum'),
        win_rate=('is_winning_trade', 'mean')
    ).round(4)
    sentiment_summary.to_csv('sentiment_performance_summary.csv')

    # Save the trader performance categories
    trader_performance.to_csv('trader_performance_categories.csv')

    print("\nKey datasets exported successfully:")
    print("- sentiment_performance_summary.csv")
    print("- trader_performance_categories.csv")

# Run the export function
export_data()

print("\n\nâœ… Analysis complete! All reports and data files have been generated.")